{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cleantext\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading csv file: 100%|██████████| 10000/10000 [00:00<00:00, 32913.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set a chunk size (e.g., 1000 rows per chunk, adjust based on file size)\n",
    "chunk_size = 1000\n",
    "rows = 10000\n",
    "chunks = []\n",
    "\n",
    "# Use tqdm to show progress while iterating over chunks\n",
    "with tqdm(desc=\"Loading csv file\", total=rows) as pbar:\n",
    "    for chunk in pd.read_csv(\"fake_news_dataset/10,000_data_raw.csv\",nrows=rows, chunksize=chunk_size):\n",
    "        chunks.append(chunk)\n",
    "        pbar.update(chunk_size)\n",
    "\n",
    "# Combine all chunks into a single DataFrame\n",
    "df = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are as expected.\n"
     ]
    }
   ],
   "source": [
    "if len(df.columns) == 18:\n",
    "    print(\"Too many columns, removing first\")\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "else:\n",
    "    print(\"Columns are as expected.\")\n",
    "    # ? Failsafe in case an unnamed column too many appears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning med 'clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "0    plu one articl googl plu thank ali alfoneh ass...\n",
      "1    cost best senat bank committe jp morgan buy br...\n",
      "2    man awoken year coma commit suicid learn donal...\n",
      "3    julia geist ask draw pictur comput scientist l...\n",
      "4    – compil studi vaccin danger activist post sep...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df['content'] = df['content'].apply(lambda x: cleantext.clean(text=x) if isinstance(x, str) else None)\n",
    "df = df.dropna(subset=['content'])\n",
    "print(df['content'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning med 'clean_words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [plu, one, articl, googl, plu, thank, ali, alf...\n",
      "1    [cost, best, senat, bank, committ, jp, morgan,...\n",
      "2    [man, awoken, year, coma, commit, suicid, lear...\n",
      "3    [julia, geist, ask, draw, pictur, comput, scie...\n",
      "4    [–, compil, studi, vaccin, danger, activist, p...\n",
      "Name: content, dtype: object\n",
      "\n",
      "Articles Left:  10000\n"
     ]
    }
   ],
   "source": [
    "df['content'] = df['content'].apply(lambda x: cleantext.clean_words(\n",
    "    text=x,\n",
    "    clean_all=True,\n",
    "    extra_spaces=True,\n",
    "    stemming=True,\n",
    "    stopwords=True,\n",
    "    stp_lang='english',\n",
    ") if isinstance(x, str) else None)\n",
    "df = df.dropna(subset=['content'])\n",
    "\n",
    "print(df['content'].head(5))\n",
    "print(\"\\nArticles Left: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fake_news_dataset/10,000_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles left: 9339\n",
      "Reliable articles: 5395\n",
      "Fake articles: 3496\n",
      "Ratio of fakes: 0.3743\n",
      "Ratio of reliable: 0.5777\n"
     ]
    }
   ],
   "source": [
    "# Define the conversion dictionary\n",
    "convert = {\n",
    "    '': \"skip\", 'conspiracy': '0', 'satire': '0', 'reliable': '1',\n",
    "    'unreliable': 'skip', 'junksci': '0', 'unknown': 'skip',\n",
    "    'political': '1', 'fake': '0', 'hate': '0',\n",
    "    'clickbait': '1', 'bias': '1', 'rumor': '0'\n",
    "}\n",
    "\n",
    "# Create a new column with converted categories\n",
    "df['processed_category'] = df.iloc[:, 3].map(convert)\n",
    "df[\"type\"] = df[\"processed_category\"]\n",
    "# df.drop(columns=['processed_category'], inplace=True)\n",
    "# Filter out 'skip' categories\n",
    "df = df[df['type'] != 'skip']\n",
    "\n",
    "# Count fake and reliable articles\n",
    "fake_count = (df['type'] == '0').sum()\n",
    "real_count = (df['type'] == '1').sum()\n",
    "total_count = len(df)\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Number of articles left: {total_count}\")\n",
    "print(f\"Reliable articles: {real_count}\")\n",
    "print(f\"Fake articles: {fake_count}\")\n",
    "print(f\"Ratio of fakes: {fake_count/total_count:.4f}\")\n",
    "print(f\"Ratio of reliable: {real_count/total_count:.4f}\")\n",
    "\n",
    "# Optional: If you want to reset the index after filtering\n",
    "df_filtered = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(3496), np.int64(5395))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_count, real_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fake_news_dataset/10,000_data_cleaned_fr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning LIAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>5473.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>There are a larger number of shark attacks in ...</td>\n",
       "      <td>animals,elections</td>\n",
       "      <td>aclu-florida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>interview on \"The Colbert Report\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>3408.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Democrats have now become the party of the [At...</td>\n",
       "      <td>elections</td>\n",
       "      <td>alan-powell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>an interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>3959.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>Says an alternative to Social Security that op...</td>\n",
       "      <td>retirement,social-security</td>\n",
       "      <td>herman-cain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>republican</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>a Republican presidential debate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>2253.json</td>\n",
       "      <td>false</td>\n",
       "      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n",
       "      <td>florida,foreign-policy</td>\n",
       "      <td>jeff-greene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a televised debate on Miami's WPLG-10 against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10239</th>\n",
       "      <td>1155.json</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>The Department of Veterans Affairs has a manua...</td>\n",
       "      <td>health-care,veterans</td>\n",
       "      <td>michael-steele</td>\n",
       "      <td>chairman of the Republican National Committee</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a Fox News interview</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10240 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1   \\\n",
       "0       2635.json        false   \n",
       "1      10540.json    half-true   \n",
       "2        324.json  mostly-true   \n",
       "3       1123.json        false   \n",
       "4       9028.json    half-true   \n",
       "...           ...          ...   \n",
       "10235   5473.json  mostly-true   \n",
       "10236   3408.json  mostly-true   \n",
       "10237   3959.json    half-true   \n",
       "10238   2253.json        false   \n",
       "10239   1155.json   pants-fire   \n",
       "\n",
       "                                                      2   \\\n",
       "0      Says the Annies List political group supports ...   \n",
       "1      When did the decline of coal start? It started...   \n",
       "2      Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3      Health care reform legislation is likely to ma...   \n",
       "4      The economic turnaround started at the end of ...   \n",
       "...                                                  ...   \n",
       "10235  There are a larger number of shark attacks in ...   \n",
       "10236  Democrats have now become the party of the [At...   \n",
       "10237  Says an alternative to Social Security that op...   \n",
       "10238  On lifting the U.S. Cuban embargo and allowing...   \n",
       "10239  The Department of Veterans Affairs has a manua...   \n",
       "\n",
       "                                       3               4   \\\n",
       "0                                abortion    dwayne-bohac   \n",
       "1      energy,history,job-accomplishments  scott-surovell   \n",
       "2                          foreign-policy    barack-obama   \n",
       "3                             health-care    blog-posting   \n",
       "4                            economy,jobs   charlie-crist   \n",
       "...                                   ...             ...   \n",
       "10235                   animals,elections    aclu-florida   \n",
       "10236                           elections     alan-powell   \n",
       "10237          retirement,social-security     herman-cain   \n",
       "10238              florida,foreign-policy     jeff-greene   \n",
       "10239                health-care,veterans  michael-steele   \n",
       "\n",
       "                                                  5         6           7   \\\n",
       "0                               State representative     Texas  republican   \n",
       "1                                     State delegate  Virginia    democrat   \n",
       "2                                          President  Illinois    democrat   \n",
       "3                                                NaN       NaN        none   \n",
       "4                                                NaN   Florida    democrat   \n",
       "...                                              ...       ...         ...   \n",
       "10235                                            NaN   Florida        none   \n",
       "10236                                            NaN   Georgia  republican   \n",
       "10237                                            NaN   Georgia  republican   \n",
       "10238                                            NaN   Florida    democrat   \n",
       "10239  chairman of the Republican National Committee  Maryland  republican   \n",
       "\n",
       "         8     9      10     11    12  \\\n",
       "0       0.0   1.0    0.0    0.0   0.0   \n",
       "1       0.0   0.0    1.0    1.0   0.0   \n",
       "2      70.0  71.0  160.0  163.0   9.0   \n",
       "3       7.0  19.0    3.0    5.0  44.0   \n",
       "4      15.0   9.0   20.0   19.0   2.0   \n",
       "...     ...   ...    ...    ...   ...   \n",
       "10235   0.0   1.0    1.0    1.0   0.0   \n",
       "10236   0.0   0.0    0.0    1.0   0.0   \n",
       "10237   4.0  11.0    5.0    3.0   3.0   \n",
       "10238   3.0   1.0    3.0    0.0   0.0   \n",
       "10239   0.0   1.0    1.0    0.0   2.0   \n",
       "\n",
       "                                                      13  \n",
       "0                                               a mailer  \n",
       "1                                        a floor speech.  \n",
       "2                                                 Denver  \n",
       "3                                         a news release  \n",
       "4                                    an interview on CNN  \n",
       "...                                                  ...  \n",
       "10235                  interview on \"The Colbert Report\"  \n",
       "10236                                       an interview  \n",
       "10237                   a Republican presidential debate  \n",
       "10238  a televised debate on Miami's WPLG-10 against ...  \n",
       "10239                               a Fox News interview  \n",
       "\n",
       "[10240 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('liar_dataset/train.tsv', sep='\\t', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10240\n",
      "0    say anni list polit group support thirdtrimest...\n",
      "1    declin coal start start natur ga took start be...\n",
      "2    hillari clinton agre john mccain vote give geo...\n",
      "3    health care reform legisl like mandat free sex...\n",
      "4                     econom turnaround start end term\n",
      "Name: 2, dtype: object\n",
      "10240\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df[2] = df[2].apply(lambda x: cleantext.clean(x))\n",
    "df = df.dropna(subset=[2])\n",
    "print(df[2].head(5))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [say, anni, list, polit, group, support, third...\n",
      "1    [declin, coal, start, start, natur, ga, took, ...\n",
      "2    [hillari, clinton, agr, john, mccain, vote, gi...\n",
      "3    [health, care, reform, legisl, like, mandat, f...\n",
      "4               [econom, turnaround, start, end, term]\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Articles Left:  10240\n"
     ]
    }
   ],
   "source": [
    "df[2] = df[2].apply(lambda x: cleantext.clean_words(\n",
    "    text=x,\n",
    "    clean_all=True,\n",
    "    extra_spaces=True,\n",
    "    stemming=True,\n",
    "    stopwords=True,\n",
    "    stp_lang='english',\n",
    ") if isinstance(x, str) else None)\n",
    "df = df.dropna(subset=[2])\n",
    "\n",
    "print(df[2].head(5))\n",
    "print(\"\\nArticles Left: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('liar_dataset/liar_dataset_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake ratio: 0.5523\n",
      "Real ratio: 0.4477\n",
      "Total articles after filtering: 8126\n",
      "Fake articles: 4488\n",
      "Reliable articles: 3638\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define headers\n",
    "headers = [\"number\", \"id\", \"type\", \"content\", \"speaker\", \"job_title\", \"state\",\n",
    "           \"party\", \"barely_true\", \"false\", \"half_true\", \"mostly_true\", \"pants_on_fire\",\n",
    "           \"context\", \"yap\"]\n",
    "\n",
    "# Dictionary for label conversion\n",
    "convert = {\n",
    "    '': \"skip\", 'true': 1, 'half-true': 'skip', 'pants-fire': 0,\n",
    "    'mostly-true': 1, 'barely-true': 0, 'false': 0\n",
    "}\n",
    "df = pd.read_csv(\"liar_dataset/liar_dataset_cleaned.csv\") # ? Sometimes df fails when kept in memory so we load it just to be sure\n",
    "\n",
    "# Ensure the dataframe has the correct number of columns\n",
    "df = df.iloc[:, :len(headers)]\n",
    "\n",
    "# Rename columns to match headers if needed\n",
    "df.columns = headers[:len(df.columns)]\n",
    "\n",
    "# Convert categories using the dictionary\n",
    "# Use apply instead of map to handle potential list or complex data types\n",
    "df['type'] = df['type'].apply(lambda x: convert.get(str(x).lower().strip(), 'skip'))\n",
    "\n",
    "# Filter out 'skip' categories\n",
    "df_filtered = df[df['type'] != 'skip']\n",
    "\n",
    "# Count fake and reliable articles\n",
    "fake_count = (df_filtered['type'] == 0).sum()\n",
    "real_count = (df_filtered['type'] == 1).sum()\n",
    "\n",
    "# Calculate and print ratios\n",
    "total_count = len(df_filtered)\n",
    "print(f\"Fake ratio: {fake_count/total_count:.4f}\")\n",
    "print(f\"Real ratio: {real_count/total_count:.4f}\")\n",
    "\n",
    "# Save filtered dataframe to CSV\n",
    "df_filtered.to_csv('liar_dataset/liar_fr.csv', index=False)\n",
    "\n",
    "# Print additional statistics\n",
    "print(f\"Total articles after filtering: {total_count}\")\n",
    "print(f\"Fake articles: {fake_count}\")\n",
    "print(f\"Reliable articles: {real_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
