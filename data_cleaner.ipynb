{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cleantext\n",
    "import csv\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading csv file: 100%|██████████| 995000/995000 [00:22<00:00, 43346.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set a chunk size (e.g., 1000 rows per chunk, adjust based on file size)\n",
    "chunk_size = 1000\n",
    "rows = 995000\n",
    "chunks = []\n",
    "\n",
    "# Use tqdm to show progress while iterating over chunks\n",
    "with tqdm(desc=\"Loading csv file\", total=rows) as pbar:\n",
    "    for chunk in pd.read_csv(\"995,000_rows.csv\",nrows=rows, chunksize=chunk_size):\n",
    "        chunks.append(chunk)\n",
    "        pbar.update(chunk_size)\n",
    "\n",
    "# Combine all chunks into a single DataFrame\n",
    "df = pd.concat(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning med clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df))\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcleantext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.13/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.13/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.13/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.13/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df))\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcleantext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.13/site-packages/cleantext/cleantext.py:63\u001b[0m, in \u001b[0;36mclean\u001b[0;34m(text, clean_all, extra_spaces, stemming, stopwords, lowercase, numbers, punct, reg, reg_replace, stp_lang)\u001b[0m\n\u001b[1;32m     61\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([_ \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m text \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _\u001b[38;5;241m.\u001b[39misdigit()])\n\u001b[1;32m     62\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m---> 63\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[43mps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens\n\u001b[1;32m     64\u001b[0m                      \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words])\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_spaces:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.13/site-packages/nltk/stem/porter.py:675\u001b[0m, in \u001b[0;36mPorterStemmer.stem\u001b[0;34m(self, word, to_lowercase)\u001b[0m\n\u001b[1;32m    673\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step1c(stem)\n\u001b[1;32m    674\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step2(stem)\n\u001b[0;32m--> 675\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step4(stem)\n\u001b[1;32m    677\u001b[0m stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step5a(stem)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.13/site-packages/nltk/stem/porter.py:532\u001b[0m, in \u001b[0;36mPorterStemmer._step3\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_step3\u001b[39m(\u001b[38;5;28mself\u001b[39m, word):\n\u001b[1;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implements Step 3 from \"An algorithm for suffix stripping\"\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    From the paper:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m        (m>0) NESS  ->                  goodness       ->  good\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_rule_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43micate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_positive_measure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mative\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_positive_measure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_positive_measure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miciti\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_positive_measure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_positive_measure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mful\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_positive_measure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_positive_measure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.13/site-packages/nltk/stem/porter.py:266\u001b[0m, in \u001b[0;36mPorterStemmer._apply_rule_list\u001b[0;34m(self, word, rules)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;66;03m# Don't try any further rules\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m word\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    267\u001b[0m     stem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace_suffix(word, suffix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m condition \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m condition(stem):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df['content'] = df['content'].apply(lambda x: cleantext.clean(text=x) if isinstance(x, str) else None)\n",
    "df = df.dropna(subset=['content'])\n",
    "print(df['content'].head(5))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning med clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(lambda x: cleantext.clean_words(\n",
    "    text=x,\n",
    "    clean_all=True,\n",
    "    extra_spaces=True,\n",
    "    stemming=True,\n",
    "    stopwords=True,\n",
    "    stp_lang='english',\n",
    ") if isinstance(x, str) else None)\n",
    "df = df.dropna(subset=['content'])\n",
    "\n",
    "print(df['content'].head(5))\n",
    "print(\"\\nArticles Left: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on row:  ['908192', '', 'Financials   7:50am EST BRIEF-Al Tawfeek Co for Financial Leasing Q3 profit rises \\nNov 13 Al Tawfeek Company for Financial Leasing \\n* Q3 consol total operating revenue EGP 117.2 million versus EGP 102.2 million year ago \\n* Q3 consol net profit EGP 8.7 million versus EGP 8.4 million year ago Source: ( bit.ly/2etVQAu ) Further company coverage: Next In Financials', '2016-11-13T15:38:41.407+02:00', '2018-02-10 13:43:39.521661', '2018-02-10 13:43:39.521686', \"['briefal', 'tawfeek', 'co', 'financ', 'lea', 'q', 'profit', 'rise']\", '', '', '', '', '', '', 'webhose', '', '', '', '']\n",
      "Number of articles left: 868346\n",
      "Reliable articles: 573725\n",
      "Fake articles: 294621\n",
      "Ratio of fakes: 0.33928986832437763\n",
      "Ratio of reliable: 0.6607101316756224\n"
     ]
    }
   ],
   "source": [
    "temp = [] \n",
    "convert = {\n",
    "    '': \"skip\", 'conspiracy': 'fake', 'satire': 'fake', 'reliable': 'reliable',\n",
    "    'unreliable': 'skip', 'junksci': 'fake', 'unknown': 'skip',\n",
    "    'political': 'reliable', 'fake': 'fake', 'hate': 'fake',\n",
    "    'clickbait': 'reliable', 'bias': 'reliable', 'rumor': 'fake'\n",
    "}\n",
    "\n",
    "fakeCount = 0 \n",
    "realCount = 0 \n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "with open(\"data_cleaned.csv\", \"r\") as src: \n",
    "    reader = csv.reader(src) \n",
    "    header = next(reader)\n",
    "        \n",
    "    for row in reader:  \n",
    "        try:\n",
    "            row[4] = convert[row[4]]  # Convert category using the dictionary\n",
    "                \n",
    "            if row[4] == \"fake\":   # 0 for fake\n",
    "                fakeCount += 1  # Increment fake count\n",
    "            elif row[4] == \"reliable\": # 1 for reliable\n",
    "                realCount += 1  # Increment real count\n",
    "                \n",
    "            if row[4] != \"skip\":  # Skip unwanted categories\n",
    "                temp.append(row)  # Append valid rows to the list\n",
    "                # print(row[4])\n",
    "        except Exception as e:\n",
    "            # Skip the bad rows\n",
    "            print(\"Error on row: \", row)\n",
    "            continue\n",
    "            \n",
    "\n",
    "# Create a DataFrame from the filtered list, keeping the original column names\n",
    "df = pd.DataFrame(temp, columns=header)\n",
    "\n",
    "# Print the ratio of fake vs. real news articles and number of articles\n",
    "print(f\"Number of articles left: {len(temp)}\")\n",
    "print(f\"Reliable articles: {realCount}\")\n",
    "print(f\"Fake articles: {fakeCount}\")\n",
    "print(f\"Ratio of fakes: {fakeCount/(fakeCount+realCount)}\")\n",
    "print(f\"Ratio of reliable: {realCount/(fakeCount+realCount)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sk/gc_zj2g97g1fq09yllwgnmhm0000gn/T/ipykernel_59018/3782972487.py:12: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data_cleaned.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles left: 916122\n",
      "Reliable articles: 573725\n",
      "Fake articles: 294621\n",
      "Ratio of fakes: 0.3216\n",
      "Ratio of reliable: 0.6263\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the conversion dictionary\n",
    "convert = {\n",
    "    '': \"skip\", 'conspiracy': 'fake', 'satire': 'fake', 'reliable': 'reliable',\n",
    "    'unreliable': 'skip', 'junksci': 'fake', 'unknown': 'skip',\n",
    "    'political': 'reliable', 'fake': 'fake', 'hate': 'fake',\n",
    "    'clickbait': 'reliable', 'bias': 'reliable', 'rumor': 'fake'\n",
    "}\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"data_cleaned.csv\")\n",
    "\n",
    "# Create a new column with converted categories\n",
    "df['processed_category'] = df.iloc[:, 4].map(convert)\n",
    "\n",
    "# Filter out 'skip' categories\n",
    "df_filtered = df[df['processed_category'] != 'skip']\n",
    "\n",
    "# Count fake and reliable articles\n",
    "fake_count = (df_filtered['processed_category'] == 'fake').sum()\n",
    "real_count = (df_filtered['processed_category'] == 'reliable').sum()\n",
    "total_count = len(df_filtered)\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Number of articles left: {total_count}\")\n",
    "print(f\"Reliable articles: {real_count}\")\n",
    "print(f\"Fake articles: {fake_count}\")\n",
    "print(f\"Ratio of fakes: {fake_count/total_count:.4f}\")\n",
    "print(f\"Ratio of reliable: {real_count/total_count:.4f}\")\n",
    "\n",
    "# Optional: If you want to reset the index after filtering\n",
    "df_filtered = df_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294621, 573725)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakeCount, realCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_cleaned_fr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning LIAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>5473.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>There are a larger number of shark attacks in ...</td>\n",
       "      <td>animals,elections</td>\n",
       "      <td>aclu-florida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>interview on \"The Colbert Report\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>3408.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Democrats have now become the party of the [At...</td>\n",
       "      <td>elections</td>\n",
       "      <td>alan-powell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>an interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>3959.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>Says an alternative to Social Security that op...</td>\n",
       "      <td>retirement,social-security</td>\n",
       "      <td>herman-cain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>republican</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>a Republican presidential debate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>2253.json</td>\n",
       "      <td>false</td>\n",
       "      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n",
       "      <td>florida,foreign-policy</td>\n",
       "      <td>jeff-greene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a televised debate on Miami's WPLG-10 against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10239</th>\n",
       "      <td>1155.json</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>The Department of Veterans Affairs has a manua...</td>\n",
       "      <td>health-care,veterans</td>\n",
       "      <td>michael-steele</td>\n",
       "      <td>chairman of the Republican National Committee</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a Fox News interview</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10240 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1   \\\n",
       "0       2635.json        false   \n",
       "1      10540.json    half-true   \n",
       "2        324.json  mostly-true   \n",
       "3       1123.json        false   \n",
       "4       9028.json    half-true   \n",
       "...           ...          ...   \n",
       "10235   5473.json  mostly-true   \n",
       "10236   3408.json  mostly-true   \n",
       "10237   3959.json    half-true   \n",
       "10238   2253.json        false   \n",
       "10239   1155.json   pants-fire   \n",
       "\n",
       "                                                      2   \\\n",
       "0      Says the Annies List political group supports ...   \n",
       "1      When did the decline of coal start? It started...   \n",
       "2      Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3      Health care reform legislation is likely to ma...   \n",
       "4      The economic turnaround started at the end of ...   \n",
       "...                                                  ...   \n",
       "10235  There are a larger number of shark attacks in ...   \n",
       "10236  Democrats have now become the party of the [At...   \n",
       "10237  Says an alternative to Social Security that op...   \n",
       "10238  On lifting the U.S. Cuban embargo and allowing...   \n",
       "10239  The Department of Veterans Affairs has a manua...   \n",
       "\n",
       "                                       3               4   \\\n",
       "0                                abortion    dwayne-bohac   \n",
       "1      energy,history,job-accomplishments  scott-surovell   \n",
       "2                          foreign-policy    barack-obama   \n",
       "3                             health-care    blog-posting   \n",
       "4                            economy,jobs   charlie-crist   \n",
       "...                                   ...             ...   \n",
       "10235                   animals,elections    aclu-florida   \n",
       "10236                           elections     alan-powell   \n",
       "10237          retirement,social-security     herman-cain   \n",
       "10238              florida,foreign-policy     jeff-greene   \n",
       "10239                health-care,veterans  michael-steele   \n",
       "\n",
       "                                                  5         6           7   \\\n",
       "0                               State representative     Texas  republican   \n",
       "1                                     State delegate  Virginia    democrat   \n",
       "2                                          President  Illinois    democrat   \n",
       "3                                                NaN       NaN        none   \n",
       "4                                                NaN   Florida    democrat   \n",
       "...                                              ...       ...         ...   \n",
       "10235                                            NaN   Florida        none   \n",
       "10236                                            NaN   Georgia  republican   \n",
       "10237                                            NaN   Georgia  republican   \n",
       "10238                                            NaN   Florida    democrat   \n",
       "10239  chairman of the Republican National Committee  Maryland  republican   \n",
       "\n",
       "         8     9      10     11    12  \\\n",
       "0       0.0   1.0    0.0    0.0   0.0   \n",
       "1       0.0   0.0    1.0    1.0   0.0   \n",
       "2      70.0  71.0  160.0  163.0   9.0   \n",
       "3       7.0  19.0    3.0    5.0  44.0   \n",
       "4      15.0   9.0   20.0   19.0   2.0   \n",
       "...     ...   ...    ...    ...   ...   \n",
       "10235   0.0   1.0    1.0    1.0   0.0   \n",
       "10236   0.0   0.0    0.0    1.0   0.0   \n",
       "10237   4.0  11.0    5.0    3.0   3.0   \n",
       "10238   3.0   1.0    3.0    0.0   0.0   \n",
       "10239   0.0   1.0    1.0    0.0   2.0   \n",
       "\n",
       "                                                      13  \n",
       "0                                               a mailer  \n",
       "1                                        a floor speech.  \n",
       "2                                                 Denver  \n",
       "3                                         a news release  \n",
       "4                                    an interview on CNN  \n",
       "...                                                  ...  \n",
       "10235                  interview on \"The Colbert Report\"  \n",
       "10236                                       an interview  \n",
       "10237                   a Republican presidential debate  \n",
       "10238  a televised debate on Miami's WPLG-10 against ...  \n",
       "10239                               a Fox News interview  \n",
       "\n",
       "[10240 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('liar_dataset/train.tsv', sep='\\t', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10240\n",
      "0    say anni list polit group support thirdtrimest...\n",
      "1    declin coal start start natur ga took start be...\n",
      "2    hillari clinton agre john mccain vote give geo...\n",
      "3    health care reform legisl like mandat free sex...\n",
      "4                     econom turnaround start end term\n",
      "Name: 2, dtype: object\n",
      "10240\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df[2] = df[2].apply(lambda x: cleantext.clean(text=x) if isinstance(x, str) else None)\n",
    "df = df.dropna(subset=[2])\n",
    "print(df[2].head(5))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [say, anni, list, polit, group, support, third...\n",
      "1    [declin, coal, start, start, natur, ga, took, ...\n",
      "2    [hillari, clinton, agr, john, mccain, vote, gi...\n",
      "3    [health, care, reform, legisl, like, mandat, f...\n",
      "4               [econom, turnaround, start, end, term]\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Articles Left:  10240\n"
     ]
    }
   ],
   "source": [
    "df[2] = df[2].apply(lambda x: cleantext.clean_words(\n",
    "    text=x,\n",
    "    clean_all=True,\n",
    "    extra_spaces=True,\n",
    "    stemming=True,\n",
    "    stopwords=True,\n",
    "    stp_lang='english',\n",
    ") if isinstance(x, str) else None)\n",
    "df = df.dropna(subset=[2])\n",
    "\n",
    "print(df[2].head(5))\n",
    "print(\"\\nArticles Left: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('liar_dataset_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
