{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'clean_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mclean_text\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcl1\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'clean_text'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import clean_text as cl1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning med clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = \"data_raw.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Determine chunk size\n",
    "num_splits = 50\n",
    "chunk_size = len(df) // num_splits\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"split_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Split and save each part\n",
    "for i in range(num_splits):\n",
    "    start = i * chunk_size\n",
    "    end = start + chunk_size if i < num_splits - 1 else len(df)  # Ensure last file gets remaining rows\n",
    "    chunk_df = df.iloc[start:end]\n",
    "    \n",
    "    output_file = os.path.join(output_dir, f\"part_{i+1}.csv\")\n",
    "    chunk_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Split into {num_splits} files inside '{output_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the CSV\n",
    "df = pd.read_csv('data_test.csv')\n",
    "\n",
    "# Applying the cleaning function to the 'content' column\n",
    "df['content'] = df['content'].apply(lambda x: cleantext.clean( \n",
    "    text=x,\n",
    "    lower=True,\n",
    "    no_line_breaks=True,\n",
    "    normalize_whitespace=True,\n",
    "    no_urls=True,\n",
    "    no_numbers=True,\n",
    "    no_emails=True,\n",
    "    no_currency_symbols=True,\n",
    "    no_digits=True,\n",
    "    no_punct=True,\n",
    "    replace_with_number = \"<NUM>\",\n",
    "    lang='en'\n",
    "))\n",
    "\n",
    "df['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning med cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cleantext' has no attribute 'clean_words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcleantext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_words\u001b[49m(\n\u001b[1;32m      2\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m     clean_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# Execute all cleaning operations\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     extra_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Remove extra white spaces \u001b[39;00m\n\u001b[1;32m      5\u001b[0m     stemming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m# Stem the words\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     stopwords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[38;5;66;03m# Remove stop words\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     stp_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Language for stop words\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cleantext' has no attribute 'clean_words'"
     ]
    }
   ],
   "source": [
    "df['content'] = cleantext.clean_words(\n",
    "    df['content'],\n",
    "    clean_all=False, # Execute all cleaning operations\n",
    "    extra_spaces=True,  # Remove extra white spaces \n",
    "    stemming=True, # Stem the words\n",
    "    stopwords=True,# Remove stop words\n",
    "    stp_lang='english',  # Language for stop words\n",
    ")\n",
    "\n",
    "df['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
